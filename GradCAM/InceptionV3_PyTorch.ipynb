{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InceptionV3_PyTorch.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0mUU3RdKuu2O"},"source":["from collections import namedtuple\n","import warnings\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.jit.annotations import Optional\n","from torch import Tensor\n","#from .utils import load_state_dict_from_url"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7rl-UN-uwl2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607096717447,"user_tz":300,"elapsed":24574,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"bae7c94d-1d1a-44c5-c498-17f1b77f9555"},"source":["# Real v. Synthesized Image\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RZMeesf9u2am"},"source":["import sys\n","import os\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zv5v6i4bBmdf"},"source":["import torchvision\n","from torchvision import transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkToa-jWrAHg","executionInfo":{"status":"ok","timestamp":1607050915586,"user_tz":300,"elapsed":703,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"d8ad9cf3-65d9-4dc4-e081-324115b8ffb8"},"source":["# move all files and folders from one directory to another directory.\n","# ! mv  -v '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/'* '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/_finished.txt' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/_finished.txt'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/log.txt' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/log.txt'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/run.txt' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/run.txt'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/seed0066.png' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/seed0066.png'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/seed0230.png' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/seed0230.png'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/seed0389.png' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/seed0389.png'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/seed1518.png' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/seed1518.png'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/submit_config.pkl' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/submit_config.pkl'\n","renamed '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/00000-generate-images/submit_config.txt' -> '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/submit_config.txt'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y3buLpqqdof1"},"source":["import os\n","import shutil\n","destination_dir = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/png1024/'\n","source = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FFHQ/images1024x1024/train/'\n","def copyfiles(source, destination_dir):\n","  for root, dirs, files in tqdm(os.walk(source)):  # replace the . with your starting directory\n","    for file in files:\n","        path_file = os.path.join(root,file)\n","        shutil.copy2(path_file,destination_dir) # change you destination dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"robtFE2lnQdN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607111979269,"user_tz":300,"elapsed":15605,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"4dacce9a-a8f7-4919-b616-d1197307d31b"},"source":["destination_dir = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/data/train/FFHQ/'\n","source = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/jpeg512/'\n","copyfiles(source, destination_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19552.jpeg\n","19173.jpeg\n","19496.jpeg\n","19390.jpeg\n","19511.jpeg\n","31687.jpeg\n","31766.jpeg\n","31025.jpeg\n","31403.jpeg\n","31541.jpeg\n","31342.jpeg\n","31139.jpeg\n","31547.jpeg\n","31756.jpeg\n","31603.jpeg\n","31349.jpeg\n","42033.jpeg\n","42355.jpeg\n","42168.jpeg\n","42227.jpeg\n","42474.jpeg\n","42802.jpeg\n","42957.jpeg\n","42410.jpeg\n","42452.jpeg\n","42946.jpeg\n","51775.jpeg\n","51095.jpeg\n","51524.jpeg\n","51941.jpeg\n","51878.jpeg\n","51856.jpeg\n","51274.jpeg\n","51865.jpeg\n","51448.jpeg\n","51360.jpeg\n","51425.jpeg\n","51582.jpeg\n","51399.jpeg\n","51185.jpeg\n","02520.jpeg\n","02294.jpeg\n","02263.jpeg\n","02896.jpeg\n","02578.jpeg\n","02850.jpeg\n","02592.jpeg\n","02635.jpeg\n","02552.jpeg\n","55409.jpeg\n","55494.jpeg\n","55228.jpeg\n","55066.jpeg\n","55731.jpeg\n","55025.jpeg\n","55042.jpeg\n","55241.jpeg\n","55203.jpeg\n","55230.jpeg\n","55648.jpeg\n","55031.jpeg\n","55986.jpeg\n","28952.jpeg\n","28777.jpeg\n","28259.jpeg\n","28689.jpeg\n","28332.jpeg\n","28709.jpeg\n","28013.jpeg\n","28868.jpeg\n","28906.jpeg\n","28308.jpeg\n","28562.jpeg\n","04207.jpeg\n","04633.jpeg\n","04936.jpeg\n","04403.jpeg\n","04869.jpeg\n","32559.jpeg\n","32112.jpeg\n","32574.jpeg\n","32703.jpeg\n","32408.jpeg\n","32739.jpeg\n","32214.jpeg\n","32677.jpeg\n","32165.jpeg\n","32875.jpeg\n","32806.jpeg\n","16119.jpeg\n","16188.jpeg\n","16933.jpeg\n","16861.jpeg\n","16496.jpeg\n","16646.jpeg\n","16334.jpeg\n","16655.jpeg\n","16999.jpeg\n","16632.jpeg\n","16244.jpeg\n","16436.jpeg\n","16653.jpeg\n","16552.jpeg\n","00490.jpeg\n","00869.jpeg\n","00466.jpeg\n","00897.jpeg\n","00159.jpeg\n","00525.jpeg\n","00646.jpeg\n","00333.jpeg\n","00581.jpeg\n","00949.jpeg\n","00060.jpeg\n","00713.jpeg\n","00226.jpeg\n","09404.jpeg\n","09079.jpeg\n","09821.jpeg\n","09374.jpeg\n","09913.jpeg\n","09585.jpeg\n","09491.jpeg\n","09204.jpeg\n","09690.jpeg\n","09928.jpeg\n","09185.jpeg\n","09681.jpeg\n","09594.jpeg\n","09385.jpeg\n","09490.jpeg\n","09713.jpeg\n","59470.jpeg\n","59484.jpeg\n","59305.jpeg\n","59045.jpeg\n","59529.jpeg\n","59941.jpeg\n","59569.jpeg\n","59813.jpeg\n","59753.jpeg\n","59082.jpeg\n","59065.jpeg\n","59910.jpeg\n","59770.jpeg\n","37526.jpeg\n","37389.jpeg\n","37366.jpeg\n","37317.jpeg\n","37331.jpeg\n","37696.jpeg\n","37040.jpeg\n","37859.jpeg\n","37861.jpeg\n","37151.jpeg\n","37780.jpeg\n","37011.jpeg\n","44750.jpeg\n","44999.jpeg\n","44066.jpeg\n","44709.jpeg\n","44180.jpeg\n","44710.jpeg\n","44663.jpeg\n","44320.jpeg\n","44168.jpeg\n","44571.jpeg\n","05612.jpeg\n","05757.jpeg\n","05034.jpeg\n","05022.jpeg\n","05889.jpeg\n","05102.jpeg\n","05337.jpeg\n","05827.jpeg\n","05779.jpeg\n","05566.jpeg\n","05275.jpeg\n","05426.jpeg\n","05244.jpeg\n","05121.jpeg\n","05263.jpeg\n","14439.jpeg\n","14782.jpeg\n","14196.jpeg\n","14460.jpeg\n","14252.jpeg\n","14414.jpeg\n","14786.jpeg\n","14283.jpeg\n","14269.jpeg\n","14625.jpeg\n","14090.jpeg\n","14915.jpeg\n","14929.jpeg\n","14112.jpeg\n","14837.jpeg\n","36942.jpeg\n","36330.jpeg\n","36633.jpeg\n","36743.jpeg\n","36338.jpeg\n","36371.jpeg\n","36347.jpeg\n","36401.jpeg\n","36747.jpeg\n","36671.jpeg\n","06728.jpeg\n","06040.jpeg\n","06088.jpeg\n","06995.jpeg\n","06872.jpeg\n","06367.jpeg\n","06523.jpeg\n","06743.jpeg\n","06200.jpeg\n","06137.jpeg\n","06454.jpeg\n","06429.jpeg\n","06151.jpeg\n","06147.jpeg\n","06892.jpeg\n","06890.jpeg\n","06697.jpeg\n","35886.jpeg\n","35485.jpeg\n","35044.jpeg\n","35697.jpeg\n","35053.jpeg\n","35686.jpeg\n","35001.jpeg\n","35960.jpeg\n","35138.jpeg\n","35069.jpeg\n","35246.jpeg\n","35953.jpeg\n","35577.jpeg\n","35951.jpeg\n","35211.jpeg\n","35148.jpeg\n","35722.jpeg\n","45431.jpeg\n","45757.jpeg\n","45750.jpeg\n","45481.jpeg\n","45280.jpeg\n","45184.jpeg\n","45576.jpeg\n","45687.jpeg\n","45609.jpeg\n","45365.jpeg\n","45031.jpeg\n","45854.jpeg\n","33802.jpeg\n","33929.jpeg\n","33723.jpeg\n","33620.jpeg\n","33734.jpeg\n","33411.jpeg\n","33705.jpeg\n","33542.jpeg\n","33741.jpeg\n","33207.jpeg\n","56154.jpeg\n","56890.jpeg\n","56944.jpeg\n","56599.jpeg\n","56043.jpeg\n","56291.jpeg\n","56959.jpeg\n","56318.jpeg\n","56999.jpeg\n","56126.jpeg\n","56057.jpeg\n","50968.jpeg\n","50102.jpeg\n","50705.jpeg\n","50431.jpeg\n","50244.jpeg\n","50286.jpeg\n","50347.jpeg\n","34377.jpeg\n","34433.jpeg\n","34905.jpeg\n","34611.jpeg\n","34941.jpeg\n","34119.jpeg\n","34850.jpeg\n","34025.jpeg\n","34538.jpeg\n","40285.jpeg\n","40019.jpeg\n","40124.jpeg\n","40165.jpeg\n","40706.jpeg\n","40609.jpeg\n","40663.jpeg\n","40102.jpeg\n","40480.jpeg\n","47729.jpeg\n","47374.jpeg\n","47030.jpeg\n","47877.jpeg\n","47099.jpeg\n","47625.jpeg\n","47706.jpeg\n","47567.jpeg\n","47990.jpeg\n","47537.jpeg\n","47530.jpeg\n","47961.jpeg\n","38967.jpeg\n","38492.jpeg\n","38093.jpeg\n","38392.jpeg\n","38756.jpeg\n","38229.jpeg\n","38233.jpeg\n","38370.jpeg\n","38227.jpeg\n","38782.jpeg\n","48256.jpeg\n","48739.jpeg\n","48259.jpeg\n","48926.jpeg\n","48740.jpeg\n","48208.jpeg\n","48468.jpeg\n","48119.jpeg\n","48413.jpeg\n","17586.jpeg\n","17077.jpeg\n","17567.jpeg\n","17135.jpeg\n","17765.jpeg\n","17130.jpeg\n","17141.jpeg\n","17692.jpeg\n","17675.jpeg\n","17792.jpeg\n","27936.jpeg\n","27250.jpeg\n","27264.jpeg\n","27903.jpeg\n","27764.jpeg\n","27137.jpeg\n","27290.jpeg\n","27581.jpeg\n","27015.jpeg\n","27099.jpeg\n","27811.jpeg\n","27367.jpeg\n","01192.jpeg\n","01983.jpeg\n","01326.jpeg\n","01197.jpeg\n","01627.jpeg\n","01025.jpeg\n","01169.jpeg\n","01408.jpeg\n","01183.jpeg\n","01990.jpeg\n","01917.jpeg\n","01358.jpeg\n","01367.jpeg\n","01438.jpeg\n","01360.jpeg\n","01415.jpeg\n","46536.jpeg\n","46656.jpeg\n","46925.jpeg\n","46680.jpeg\n","46038.jpeg\n","46838.jpeg\n","46473.jpeg\n","30085.jpeg\n","30405.jpeg\n","30413.jpeg\n","30961.jpeg\n","30188.jpeg\n","30975.jpeg\n","30451.jpeg\n","30370.jpeg\n","30324.jpeg\n","30821.jpeg\n","30890.jpeg\n","30303.jpeg\n","30410.jpeg\n","30243.jpeg\n","30725.jpeg\n","30782.jpeg\n","30170.jpeg\n","20196.jpeg\n","20557.jpeg\n","20202.jpeg\n","20703.jpeg\n","20560.jpeg\n","20937.jpeg\n","20239.jpeg\n","20875.jpeg\n","20834.jpeg\n","20443.jpeg\n","20719.jpeg\n","20138.jpeg\n","20476.jpeg\n","20645.jpeg\n","24719.jpeg\n","24026.jpeg\n","24754.jpeg\n","24057.jpeg\n","24283.jpeg\n","24811.jpeg\n","24174.jpeg\n","24314.jpeg\n","24983.jpeg\n","24961.jpeg\n","24203.jpeg\n","24734.jpeg\n","08815.jpeg\n","08545.jpeg\n","08524.jpeg\n","08116.jpeg\n","08672.jpeg\n","08611.jpeg\n","08554.jpeg\n","08343.jpeg\n","08377.jpeg\n","08736.jpeg\n","08655.jpeg\n","08542.jpeg\n","08748.jpeg\n","08775.jpeg\n","49560.jpeg\n","49549.jpeg\n","49411.jpeg\n","49356.jpeg\n","49365.jpeg\n","49604.jpeg\n","49392.jpeg\n","49884.jpeg\n","49865.jpeg\n","49731.jpeg\n","49042.jpeg\n","49140.jpeg\n","49857.jpeg\n","49347.jpeg\n","49990.jpeg\n","49320.jpeg\n","53498.jpeg\n","53510.jpeg\n","53983.jpeg\n","53895.jpeg\n","53833.jpeg\n","53596.jpeg\n","53888.jpeg\n","53500.jpeg\n","53499.jpeg\n","53851.jpeg\n","53010.jpeg\n","53037.jpeg\n","12358.jpeg\n","12029.jpeg\n","12877.jpeg\n","12385.jpeg\n","12039.jpeg\n","12680.jpeg\n","12945.jpeg\n","12946.jpeg\n","12301.jpeg\n","12664.jpeg\n","12880.jpeg\n","12225.jpeg\n","12598.jpeg\n","12360.jpeg\n","12133.jpeg\n","12528.jpeg\n","10724.jpeg\n","10786.jpeg\n","10865.jpeg\n","10540.jpeg\n","10966.jpeg\n","10468.jpeg\n","10537.jpeg\n","10550.jpeg\n","10193.jpeg\n","10462.jpeg\n","10800.jpeg\n","10708.jpeg\n","10529.jpeg\n","57871.jpeg\n","57652.jpeg\n","57765.jpeg\n","57256.jpeg\n","57117.jpeg\n","57666.jpeg\n","57118.jpeg\n","57598.jpeg\n","57025.jpeg\n","57859.jpeg\n","57530.jpeg\n","57060.jpeg\n","57522.jpeg\n","57198.jpeg\n","23666.jpeg\n","23631.jpeg\n","23362.jpeg\n","23377.jpeg\n","23894.jpeg\n","23260.jpeg\n","23002.jpeg\n","23369.jpeg\n","23941.jpeg\n","23094.jpeg\n","23871.jpeg\n","23636.jpeg\n","23746.jpeg\n","23508.jpeg\n","23415.jpeg\n","29799.jpeg\n","29989.jpeg\n","29928.jpeg\n","29038.jpeg\n","29097.jpeg\n","29166.jpeg\n","29160.jpeg\n","29279.jpeg\n","29842.jpeg\n","29911.jpeg\n","29649.jpeg\n","29267.jpeg\n","29022.jpeg\n","13573.jpeg\n","13417.jpeg\n","13901.jpeg\n","13145.jpeg\n","13572.jpeg\n","13045.jpeg\n","13640.jpeg\n","13500.jpeg\n","13480.jpeg\n","13880.jpeg\n","13247.jpeg\n","13087.jpeg\n","25758.jpeg\n","25807.jpeg\n","25515.jpeg\n","25447.jpeg\n","25279.jpeg\n","25732.jpeg\n","25186.jpeg\n","25898.jpeg\n","25804.jpeg\n","25101.jpeg\n","25839.jpeg\n","25011.jpeg\n","25756.jpeg\n","25450.jpeg\n","25294.jpeg\n","25579.jpeg\n","25424.jpeg\n","41330.jpeg\n","41182.jpeg\n","41586.jpeg\n","41327.jpeg\n","41696.jpeg\n","41627.jpeg\n","41101.jpeg\n","41652.jpeg\n","41598.jpeg\n","41950.jpeg\n","41872.jpeg\n","41071.jpeg\n","52202.jpeg\n","52601.jpeg\n","52575.jpeg\n","52596.jpeg\n","52741.jpeg\n","52209.jpeg\n","18150.jpeg\n","18539.jpeg\n","18851.jpeg\n","18082.jpeg\n","18067.jpeg\n","18952.jpeg\n","18508.jpeg\n","18331.jpeg\n","18350.jpeg\n","18380.jpeg\n","18003.jpeg\n","18384.jpeg\n","26068.jpeg\n","26052.jpeg\n","26540.jpeg\n","26213.jpeg\n","26878.jpeg\n","26602.jpeg\n","26921.jpeg\n","26044.jpeg\n","26686.jpeg\n","26716.jpeg\n","26672.jpeg\n","26928.jpeg\n","26251.jpeg\n","03995.jpeg\n","03598.jpeg\n","03809.jpeg\n","03648.jpeg\n","03035.jpeg\n","03143.jpeg\n","03608.jpeg\n","03115.jpeg\n","03679.jpeg\n","03217.jpeg\n","03842.jpeg\n","03449.jpeg\n","03686.jpeg\n","03164.jpeg\n","03525.jpeg\n","03347.jpeg\n","03167.jpeg\n","03810.jpeg\n","11338.jpeg\n","11550.jpeg\n","11104.jpeg\n","11019.jpeg\n","11487.jpeg\n","11367.jpeg\n","11347.jpeg\n","11281.jpeg\n","11800.jpeg\n","11229.jpeg\n","11586.jpeg\n","11494.jpeg\n","11547.jpeg\n","11964.jpeg\n","11953.jpeg\n","15466.jpeg\n","15610.jpeg\n","15387.jpeg\n","15145.jpeg\n","15503.jpeg\n","15802.jpeg\n","54377.jpeg\n","54904.jpeg\n","54899.jpeg\n","54968.jpeg\n","54737.jpeg\n","54961.jpeg\n","54080.jpeg\n","54800.jpeg\n","54694.jpeg\n","54182.jpeg\n","54225.jpeg\n","54412.jpeg\n","58875.jpeg\n","58363.jpeg\n","58569.jpeg\n","58773.jpeg\n","58373.jpeg\n","58208.jpeg\n","58297.jpeg\n","58232.jpeg\n","58911.jpeg\n","58735.jpeg\n","58192.jpeg\n","58458.jpeg\n","58623.jpeg\n","58657.jpeg\n","58513.jpeg\n","58672.jpeg\n","58677.jpeg\n","58001.jpeg\n","21640.jpeg\n","21508.jpeg\n","21593.jpeg\n","21858.jpeg\n","21576.jpeg\n","21879.jpeg\n","21332.jpeg\n","21969.jpeg\n","21494.jpeg\n","43163.jpeg\n","43137.jpeg\n","43757.jpeg\n","43988.jpeg\n","43987.jpeg\n","07290.jpeg\n","07219.jpeg\n","07129.jpeg\n","07240.jpeg\n","07444.jpeg\n","07200.jpeg\n","07442.jpeg\n","07928.jpeg\n","07090.jpeg\n","07554.jpeg\n","07568.jpeg\n","07426.jpeg\n","07693.jpeg\n","07829.jpeg\n","39993.jpeg\n","39170.jpeg\n","39864.jpeg\n","39426.jpeg\n","39115.jpeg\n","39599.jpeg\n","39234.jpeg\n","39728.jpeg\n","39800.jpeg\n","39436.jpeg\n","39251.jpeg\n","39263.jpeg\n","39551.jpeg\n","39492.jpeg\n","39312.jpeg\n","39397.jpeg\n","22265.jpeg\n","22343.jpeg\n","22293.jpeg\n","22427.jpeg\n","22350.jpeg\n","22977.jpeg\n","22723.jpeg\n","22790.jpeg\n","22510.jpeg\n","22074.jpeg\n","22530.jpeg\n","22162.jpeg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IhnphlkJnQtZ"},"source":["destination_dir = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/data/train/StyleGAN2/'\n","source = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/StyleGAN2/StyleGAN2_general/jpeg512/'\n","copyfiles(source, destination_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7t-G2wtg8wF","executionInfo":{"status":"ok","timestamp":1607098172878,"user_tz":300,"elapsed":3978,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"e7318d87-c5c1-4c60-ee2b-af30c3d4c53f"},"source":["! pip install tqdm\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dmIXbWJutz6x"},"source":["import PIL\n","from PIL import Image\n","from tqdm import tqdm\n","def extension_change(source_image_folder, destination, extension):\n","    \n","    if not os.path.exists(destination): # if it doesn't exist already\n","        os.makedirs(destination)\n","        \n","    for filename in tqdm(os.listdir(source_image_folder)):\n","      try:\n","        image = Image.open(source_image_folder + '/' + filename) \n","  \n","        head, tail = filename.split('.')\n","        filename = head + '.' + extension    \n","\n","        image = image.convert(\"RGB\")          \n","               \n","        image.save(destination + '/' + filename)\n","      except:\n","        print('PASSED: ' + filename)\n","        continue"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOIMsW6bgo6m"},"source":["# convert styleGAN2 png images to more managable and compressed jpeg images\n","source_image_folder = '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images/'\n","destination = '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images_jpeg/'\n","extension = 'jpeg'\n","extension_change(source_image_folder, destination, extension)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjeHDCO-vni7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607098262190,"user_tz":300,"elapsed":60967,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"43632585-ed56-4603-ac7d-31c1c3e6d887"},"source":["# convert real FFHQ png images to more managable and compressed jpeg images\n","source_image_folder = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/png1024/'\n","destination = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/jpeg1024/'\n","extension = 'jpeg'\n","extension_change(source_image_folder, destination, extension)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 728/728 [01:00<00:00, 12.00it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aDntZ0kCvy6l"},"source":["# Reduce size of images to a more managable 512x512\n","import cv2\n","from tqdm import tqdm\n","def rescale(source_image_folder, destination, dimension):\n","    \n","    if not os.path.exists(destination): # if it doesn't exist already\n","        os.makedirs(destination)\n","        \n","    for filename in tqdm(os.listdir(source_image_folder)):\n","        im1 = cv2.imread(source_image_folder + '/' + filename) \n","        \n","        image = cv2.resize(im1, (dimension,dimension))            \n","               \n","        cv2.imwrite(destination + '/' + filename, image)\n","        print(destination + '/' + filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJNCRIafwAay"},"source":["# convert styleGAN2 jpeg files to a more managable size of 512x512\n","source_image_folder = '/content/gdrive/Shareddrives/Advanced CV - Final Project/stylegan2-master/stylegan2-master/results/generated_images_jpeg/'\n","destination = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/StyleGan2/styleGAN2_general/jpeg512/'\n","dimension = 512\n","rescale(source_image_folder, destination, dimension)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FuZr52YwCdQ"},"source":["# convert real FFHQ png images to more managable and compressed jpeg images\n","source_image_folder = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/jpeg1024/'\n","destination = '/content/gdrive/Shareddrives/Advanced CV - Final Project/FID/data/FFHQ/jpeg512/'\n","dimension = 512\n","rescale(source_image_folder, destination, dimension)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spWIYKHVu35l"},"source":["\n","#Transforms are common image transformations, they can be chained together using\n","#compose\n","preprocess = transforms.Compose([\n","    #resizes the image to the given size\n","    #argument: desired square output size\n","    #scales the image\n","    transforms.Resize(299),\n","    #center crop: crops the image at the center, argument is the desired h,w\n","    #so here only one argument, output will be 299 x 299\n","    transforms.CenterCrop(299),\n","    #converts an image to a tensor\n","    transforms.ToTensor(),\n","    #normalize a tensor image with mean and std deviation provided\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","root_to_train_dataset = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/data/train/'\n","# root_to_test_dataset = '/Datasets//test/'\n","#6000 images in the training dataset\n","train_set = torchvision.datasets.ImageFolder(root_to_train_dataset, transform = preprocess)\n","# n/A\n","# test_set = torchvision.datasets.ImageFolder(root_to_test_dataset, transform = preprocess)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-6294_ju_Zv"},"source":["train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, drop_last = True, shuffle = True)\n","# test_loader = torch.utils.data.DataLoader(test_set, batch_size=50, drop_last = True, shuffle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xx7w4SscdDKI"},"source":["# len(test_loader.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDxfHbl08BOH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607111917883,"user_tz":300,"elapsed":511,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"86f85444-aa17-435f-8d50-f83d39cb83b4"},"source":["len(train_loader.dataset)\n","\n","import os\n","\n","path, dirs, files = next(os.walk('/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/data/train/FFHQ/'))\n","file_count = len(files)\n","print(file_count)\n","\n","path, dirs, files = next(os.walk('/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/data/train/StyleGAN2/'))\n","file_count = len(files)\n","print(file_count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","1632\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kmr77sYw0_9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607102906553,"user_tz":300,"elapsed":547441,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"5f4bd0da-d7cf-488b-d2fb-d6f3872ae588"},"source":["epoch = 10\n","lr = 1e-2\n","n_classes = 2\n","\n","print(\"processing\")\n","model = Inception3(num_classes = 2)\n","use_cuda = True\n","'check to use cuda'\n","if use_cuda and torch.cuda.is_available():\n","  print('cuda available')\n","  model.cuda()\n","\n","criterion = nn.CrossEntropyLoss()\n","optim = torch.optim.SGD(model.parameters(), lr = lr)\n","\n","for e in range(epoch):\n","  print('epoch: ' + str(e))\n","  loss_epoch = 0\n","  for x, y in train_loader:\n","    if use_cuda and torch.cuda.is_available():\n","      x = x.cuda()\n","      y = y.cuda()\n","    optim.zero_grad()\n","    y_pred = model(x)\n","    loss = criterion(y_pred, y)\n","    loss.backward()\n","    optim.step()\n","    loss_epoch += loss.item()\n","  path = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/checkpoints/' + 'epoch-{}.pt'.format(e)\n","  torch.save(model.state_dict(), path)\n","  print(f'Epoch {e}: {loss_epoch}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["processing\n","cuda available\n","epoch: 0\n","Epoch 0: 3.0228894748724997\n","epoch: 1\n","Epoch 1: 0.18274222366744652\n","epoch: 2\n","Epoch 2: 0.12149370755651034\n","epoch: 3\n","Epoch 3: 0.07748664316022769\n","epoch: 4\n","Epoch 4: 0.05026468257710803\n","epoch: 5\n","Epoch 5: 0.03748915353207849\n","epoch: 6\n","Epoch 6: 0.05721057579648914\n","epoch: 7\n","Epoch 7: 0.03251394396647811\n","epoch: 8\n","Epoch 8: 0.03155399857496377\n","epoch: 9\n","Epoch 9: 0.019368631878023734\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O24lkvjMJ6Xd"},"source":["# helper function for computing accuracy\n","def get_acc(pred, y):\n","    pred = pred.float()\n","    y = y.float()\n","    return (y==pred).sum().float()/y.size(0)*100.\n","\n","def get_model_acc(model, loader):\n","    ys = []\n","    y_preds = []\n","    for x, y in loader:\n","        #if use_cuda and torch.cuda.is_available():\n","          #x = x.cuda()\n","          #y = y.cuda()\n","        ys.append(y)\n","        # set the prediction to the one that has highest value\n","        # Note that the the output size of model(x) is (B, 10)\n","        y_preds.append(torch.argmax(model(x), dim=1))\n","    y = torch.cat(ys, dim=0)\n","    y_pred = torch.cat(y_preds, dim=0)\n","    print((y == y_pred).sum())\n","    return get_acc(y_pred, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrkPBNSvzXmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607110439669,"user_tz":300,"elapsed":590,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"9716e1a4-bc65-49fa-9a69-6efa36549b34"},"source":["e = 9\n","path = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/checkpoints/' + 'epoch-{}.pt'.format(e)\n","print(path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/checkpoints/epoch-9.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ebBQg8oUxeP8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607110682101,"user_tz":300,"elapsed":234338,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"66fbede4-7b8d-4fbb-bbfc-1ecb15d04269"},"source":["device = torch.device('cpu')\n","model = Inception3(num_classes = 2)\n","model.load_state_dict(torch.load(path, map_location=device))\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Inception3(\n","  (Conv2d_1a_3x3): BasicConv2d(\n","    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2a_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_2b_3x3): BasicConv2d(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_3b_1x1): BasicConv2d(\n","    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Conv2d_4a_3x3): BasicConv2d(\n","    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (Mixed_5b): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5c): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_5d): InceptionA(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_1): BasicConv2d(\n","      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch5x5_2): BasicConv2d(\n","      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6a): InceptionB(\n","    (branch3x3): BasicConv2d(\n","      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3): BasicConv2d(\n","      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6b): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6c): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6d): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_6e): InceptionC(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7dbl_5): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (AuxLogits): InceptionAux(\n","    (conv0): BasicConv2d(\n","      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv1): BasicConv2d(\n","      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (fc): Linear(in_features=768, out_features=2, bias=True)\n","  )\n","  (Mixed_7a): InceptionD(\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_1): BasicConv2d(\n","      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_2): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_3): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch7x7x3_4): BasicConv2d(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7b): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (Mixed_7c): InceptionE(\n","    (branch1x1): BasicConv2d(\n","      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_1): BasicConv2d(\n","      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3_2b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_1): BasicConv2d(\n","      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_2): BasicConv2d(\n","      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3a): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch3x3dbl_3b): BasicConv2d(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch_pool): BasicConv2d(\n","      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"erBUZDtUKBPI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607110953671,"user_tz":300,"elapsed":503591,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"a9bef517-93d7-404f-a268-8abfc1e89cb8"},"source":["train_acc = get_model_acc(model, train_loader)\n","print(f'Training accuracy: {train_acc}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(1632)\n","Training accuracy: 100.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u9caAQi1tcoQ"},"source":["\n","\n","\n","__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']\n","\n","\n","model_urls = {\n","    # Inception v3 ported from TensorFlow\n","    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth',\n","}\n","\n","InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])\n","InceptionOutputs.__annotations__ = {'logits': torch.Tensor, 'aux_logits': Optional[torch.Tensor]}\n","\n","# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n","# _InceptionOutputs set here for backwards compat\n","_InceptionOutputs = InceptionOutputs\n","\n","\n","def inception_v3(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Inception v3 model architecture from\n","    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n","\n","    .. note::\n","        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n","        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n","            Default: *True*\n","        transform_input (bool): If True, preprocesses the input according to the method with which it\n","            was trained on ImageNet. Default: *False*\n","    \"\"\"\n","    if pretrained:\n","        if 'transform_input' not in kwargs:\n","            kwargs['transform_input'] = True\n","        if 'aux_logits' in kwargs:\n","            original_aux_logits = kwargs['aux_logits']\n","            kwargs['aux_logits'] = True\n","        else:\n","            original_aux_logits = True\n","        model = Inception3(**kwargs)\n","        state_dict = load_state_dict_from_url(model_urls['inception_v3_google'],\n","                                              progress=progress)\n","        model.load_state_dict(state_dict)\n","        if not original_aux_logits:\n","            model.aux_logits = False\n","            del model.AuxLogits\n","        return model\n","\n","    return Inception3(**kwargs)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5E0io2fDuWPf"},"source":["\n","class BasicConv2d(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, **kwargs):\n","        super(BasicConv2d, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n","        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        return F.relu(x, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOp3NX07tvWT"},"source":["class Inception3(nn.Module):\n","\n","    def __init__(self, num_classes=1000, aux_logits=True, transform_input=False,\n","                 inception_blocks=None, init_weights=True):\n","        super(Inception3, self).__init__()\n","        if inception_blocks is None:\n","            inception_blocks = [\n","                BasicConv2d, InceptionA, InceptionB, InceptionC,\n","                InceptionD, InceptionE, InceptionAux\n","            ]\n","        assert len(inception_blocks) == 7\n","        conv_block = inception_blocks[0]\n","        inception_a = inception_blocks[1]\n","        inception_b = inception_blocks[2]\n","        inception_c = inception_blocks[3]\n","        inception_d = inception_blocks[4]\n","        inception_e = inception_blocks[5]\n","        inception_aux = inception_blocks[6]\n","\n","        self.aux_logits = aux_logits\n","        #self.transform_input = transform_input\n","        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)\n","        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)\n","        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)\n","        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)\n","        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)\n","        self.Mixed_5b = inception_a(192, pool_features=32)\n","        self.Mixed_5c = inception_a(256, pool_features=64)\n","        self.Mixed_5d = inception_a(288, pool_features=64)\n","        self.Mixed_6a = inception_b(288)\n","        self.Mixed_6b = inception_c(768, channels_7x7=128)\n","        self.Mixed_6c = inception_c(768, channels_7x7=160)\n","        self.Mixed_6d = inception_c(768, channels_7x7=160)\n","        self.Mixed_6e = inception_c(768, channels_7x7=192)\n","        if aux_logits:\n","            self.AuxLogits = inception_aux(768, num_classes)\n","        self.Mixed_7a = inception_d(768)\n","        self.Mixed_7b = inception_e(1280)\n","        self.Mixed_7c = inception_e(2048)\n","        self.fc = nn.Linear(2048, num_classes)\n","        if init_weights:\n","            for m in self.modules():\n","                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","                    import scipy.stats as stats\n","                    stddev = m.stddev if hasattr(m, 'stddev') else 0.1\n","                    X = stats.truncnorm(-2, 2, scale=stddev)\n","                    values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n","                    values = values.view(m.weight.size())\n","                    with torch.no_grad():\n","                        m.weight.copy_(values)\n","                elif isinstance(m, nn.BatchNorm2d):\n","                    nn.init.constant_(m.weight, 1)\n","                    nn.init.constant_(m.bias, 0)\n","\n","    def _transform_input(self, x):\n","        if self.transform_input:\n","            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n","            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n","            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n","            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n","        return x\n","\n","    def forward(self, x):\n","        # N x 3 x 299 x 299\n","        x = self.Conv2d_1a_3x3(x)\n","        # N x 32 x 149 x 149\n","        x = self.Conv2d_2a_3x3(x)\n","        # N x 32 x 147 x 147\n","        x = self.Conv2d_2b_3x3(x)\n","        # N x 64 x 147 x 147\n","        x = F.max_pool2d(x, kernel_size=3, stride=2)\n","        # N x 64 x 73 x 73\n","        x = self.Conv2d_3b_1x1(x)\n","        # N x 80 x 73 x 73\n","        x = self.Conv2d_4a_3x3(x)\n","        # N x 192 x 71 x 71\n","        x = F.max_pool2d(x, kernel_size=3, stride=2)\n","        # N x 192 x 35 x 35\n","        x = self.Mixed_5b(x)\n","        # N x 256 x 35 x 35\n","        x = self.Mixed_5c(x)\n","        # N x 288 x 35 x 35\n","        x = self.Mixed_5d(x)\n","        # N x 288 x 35 x 35\n","        x = self.Mixed_6a(x)\n","        # N x 768 x 17 x 17\n","        x = self.Mixed_6b(x)\n","        # N x 768 x 17 x 17\n","        x = self.Mixed_6c(x)\n","        # N x 768 x 17 x 17\n","        x = self.Mixed_6d(x)\n","        # N x 768 x 17 x 17\n","        x = self.Mixed_6e(x)\n","        # N x 768 x 17 x 17\n","        #aux_defined = self.training and self.aux_logits\n","        #if aux_defined:\n","        #    aux = self.AuxLogits(x)\n","        #else:\n","        #    aux = None\n","        # N x 768 x 17 x 17\n","        x = self.Mixed_7a(x)\n","        # N x 1280 x 8 x 8\n","        x = self.Mixed_7b(x)\n","        # N x 2048 x 8 x 8\n","        x = self.Mixed_7c(x)\n","        # N x 2048 x 8 x 8\n","        # Adaptive average pooling\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        # N x 2048 x 1 x 1\n","        x = F.dropout(x, training=self.training)\n","        # N x 2048 x 1 x 1\n","        x = torch.flatten(x, 1)\n","        # N x 2048\n","        x = self.fc(x)\n","        # N x 1000 (num_classes)\n","\n","        #return x, aux\n","        return x\n","\n","    @torch.jit.unused\n","    def eager_outputs(self, x, aux):\n","        # type: (Tensor, Optional[Tensor]) -> InceptionOutputs\n","        if self.training and self.aux_logits:\n","            return InceptionOutputs(x, aux)\n","        else:\n","            return x\n","\n","    #def forward(self, x):\n","    #    x = self._transform_input(x)\n","    #    x, aux = self._forward(x)\n","    #    aux_defined = self.training and self.aux_logits\n","    #    if torch.jit.is_scripting():\n","    #        if not aux_defined:\n","    #            warnings.warn(\"Scripted Inception3 always returns Inception3 Tuple\")\n","    #        return InceptionOutputs(x, aux)\n","    #    else:\n","    #        return self.eager_outputs(x, aux)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSkfSj8cuboL"},"source":["class InceptionA(nn.Module):\n","\n","    def __init__(self, in_channels, pool_features, conv_block=None):\n","        super(InceptionA, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n","\n","        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n","        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n","\n","        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n","        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n","        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, padding=1)\n","\n","        self.branch_pool = conv_block(in_channels, pool_features, kernel_size=1)\n","\n","    def _forward(self, x):\n","        branch1x1 = self.branch1x1(x)\n","\n","        branch5x5 = self.branch5x5_1(x)\n","        branch5x5 = self.branch5x5_2(branch5x5)\n","\n","        branch3x3dbl = self.branch3x3dbl_1(x)\n","        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n","        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n","\n","        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n","        branch_pool = self.branch_pool(branch_pool)\n","\n","        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n","        return outputs\n","\n","    def forward(self, x):\n","        outputs = self._forward(x)\n","        return torch.cat(outputs, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGo9vv1wt6bG"},"source":["class InceptionB(nn.Module):\n","\n","    def __init__(self, in_channels, conv_block=None):\n","        super(InceptionB, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n","\n","        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n","        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n","        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n","\n","    def _forward(self, x):\n","        branch3x3 = self.branch3x3(x)\n","\n","        branch3x3dbl = self.branch3x3dbl_1(x)\n","        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n","        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n","\n","        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n","\n","        outputs = [branch3x3, branch3x3dbl, branch_pool]\n","        return outputs\n","\n","    def forward(self, x):\n","        outputs = self._forward(x)\n","        return torch.cat(outputs, 1)\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KCBABV-t_pX"},"source":["class InceptionC(nn.Module):\n","\n","    def __init__(self, in_channels, channels_7x7, conv_block=None):\n","        super(InceptionC, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n","\n","        c7 = channels_7x7\n","        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n","        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n","        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n","\n","        self.branch7x7dbl_1 = conv_block(in_channels, c7, kernel_size=1)\n","        self.branch7x7dbl_2 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n","        self.branch7x7dbl_3 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n","        self.branch7x7dbl_4 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n","        self.branch7x7dbl_5 = conv_block(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n","\n","        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n","\n","    def _forward(self, x):\n","        branch1x1 = self.branch1x1(x)\n","\n","        branch7x7 = self.branch7x7_1(x)\n","        branch7x7 = self.branch7x7_2(branch7x7)\n","        branch7x7 = self.branch7x7_3(branch7x7)\n","\n","        branch7x7dbl = self.branch7x7dbl_1(x)\n","        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n","        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n","        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n","        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n","\n","        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n","        branch_pool = self.branch_pool(branch_pool)\n","\n","        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n","        return outputs\n","\n","    def forward(self, x):\n","        outputs = self._forward(x)\n","        return torch.cat(outputs, 1)\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWm478M8uHLO"},"source":["class InceptionD(nn.Module):\n","\n","    def __init__(self, in_channels, conv_block=None):\n","        super(InceptionD, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n","        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n","\n","        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n","        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n","        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))\n","        self.branch7x7x3_4 = conv_block(192, 192, kernel_size=3, stride=2)\n","\n","    def _forward(self, x):\n","        branch3x3 = self.branch3x3_1(x)\n","        branch3x3 = self.branch3x3_2(branch3x3)\n","\n","        branch7x7x3 = self.branch7x7x3_1(x)\n","        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n","        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n","        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n","\n","        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n","        outputs = [branch3x3, branch7x7x3, branch_pool]\n","        return outputs\n","\n","    def forward(self, x):\n","        outputs = self._forward(x)\n","        return torch.cat(outputs, 1)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8GcVgv-uOk4"},"source":["class InceptionE(nn.Module):\n","\n","    def __init__(self, in_channels, conv_block=None):\n","        super(InceptionE, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n","\n","        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n","        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n","        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n","\n","        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)\n","        self.branch3x3dbl_2 = conv_block(448, 384, kernel_size=3, padding=1)\n","        self.branch3x3dbl_3a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n","        self.branch3x3dbl_3b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n","\n","        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n","\n","    def _forward(self, x):\n","        branch1x1 = self.branch1x1(x)\n","\n","        branch3x3 = self.branch3x3_1(x)\n","        branch3x3 = [\n","            self.branch3x3_2a(branch3x3),\n","            self.branch3x3_2b(branch3x3),\n","        ]\n","        branch3x3 = torch.cat(branch3x3, 1)\n","\n","        branch3x3dbl = self.branch3x3dbl_1(x)\n","        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n","        branch3x3dbl = [\n","            self.branch3x3dbl_3a(branch3x3dbl),\n","            self.branch3x3dbl_3b(branch3x3dbl),\n","        ]\n","        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n","\n","        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n","        branch_pool = self.branch_pool(branch_pool)\n","\n","        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n","        return outputs\n","\n","    def forward(self, x):\n","        outputs = self._forward(x)\n","        return torch.cat(outputs, 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LARVexS4uM2Z"},"source":["class InceptionAux(nn.Module):\n","\n","    def __init__(self, in_channels, num_classes, conv_block=None):\n","        super(InceptionAux, self).__init__()\n","        if conv_block is None:\n","            conv_block = BasicConv2d\n","        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n","        self.conv1 = conv_block(128, 768, kernel_size=5)\n","        self.conv1.stddev = 0.01\n","        self.fc = nn.Linear(768, num_classes)\n","        self.fc.stddev = 0.001\n","\n","    def forward(self, x):\n","        # N x 768 x 17 x 17\n","        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n","        # N x 768 x 5 x 5\n","        x = self.conv0(x)\n","        # N x 128 x 5 x 5\n","        x = self.conv1(x)\n","        # N x 768 x 1 x 1\n","        # Adaptive average pooling\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        # N x 768 x 1 x 1\n","        x = torch.flatten(x, 1)\n","        # N x 768\n","        x = self.fc(x)\n","        # N x 1000\n","        return x\n"],"execution_count":null,"outputs":[]}]}