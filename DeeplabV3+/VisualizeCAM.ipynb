{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VisualizeCAM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMudBQeJ8TGqTYHttfHfl/q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bAimENYz8pi_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607108836649,"user_tz":300,"elapsed":23656,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}},"outputId":"0947a4b6-f2f7-40f4-e416-d8f3c5ec08cd"},"source":["# Real v. Synthesized Image\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FJlGMqkk8IEQ","executionInfo":{"status":"ok","timestamp":1607110206164,"user_tz":300,"elapsed":387,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import torchvision\n","from torchvision import transforms\n","from PIL import Image\n","\n","import sys\n","sys.path.append('/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/')\n","\n","from InceptionV3 import*"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgB88kUcMTfi","executionInfo":{"status":"ok","timestamp":1607110030871,"user_tz":300,"elapsed":433,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["preprocess = transforms.Compose([\n","    #resizes the image to the given size\n","    #argument: desired square output size\n","    #scales the image\n","    transforms.Resize(299),\n","    #center crop: crops the image at the center, argument is the desired h,w\n","    #so here only one argument, output will be 299 x 299\n","    transforms.CenterCrop(299),\n","    #converts an image to a tensor\n","    transforms.ToTensor(),\n","    #normalize a tensor image with mean and std deviation provided\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"sntcFE5Z74Hq","executionInfo":{"status":"ok","timestamp":1607110209208,"user_tz":300,"elapsed":511,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["def gradCAM(img_input, model, intensity=0.5, res=250):\n","  img = image.load_img(img_input, target_size=(299, 299))\n","  test_image = Image.open(img_input)\n","  tensor_image = preprocess(test_image)\n","\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","  x = preprocess_input(x)\n","\n","  preds = model(tensor_image)\n","  print(preds)\n","  pred = torch.argmax(preds, dim=1)\n","  # print(decode_predictions(preds)[0][0][1]) # prints the class of image\n","\n","  with tf.GradientTape() as tape:\n","    last_conv_layer = model.get_layer('conv2d_93')\n","    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n","    model_out, last_conv_layer = iterate(x)\n","    class_out = model_out[:, np.argmax(model_out[0])]\n","    grads = tape.gradient(class_out, last_conv_layer)\n","    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n","    \n","  heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n","  heatmap = np.maximum(heatmap, 0)\n","  heatmap /= np.max(heatmap)\n","  heatmap = heatmap.reshape((8, 8))\n","\n","  img = cv2.imread(img_input)\n","\n","  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n","\n","  heatmap = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n","\n","  img = heatmap * intensity + img\n","\n","  cv2_imshow(cv2.resize(cv2.imread(orig), (res, res)))\n","  cv2_imshow(cv2.resize(img, (res, res)))\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICoKNsoK8W_O","executionInfo":{"status":"ok","timestamp":1607108847675,"user_tz":300,"elapsed":17775,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["# paths to saved model dict.\n","path_to_model = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/checkpoints/epoch-9.pt'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcys0IWo8ctf"},"source":["# load model dictionary\n","device = torch.device('cpu')\n","model = Inception3(num_classes = 2)\n","model.load_state_dict(torch.load(path_to_model, map_location=device))\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cbRjaUtk79z0","executionInfo":{"status":"ok","timestamp":1607109054699,"user_tz":300,"elapsed":728,"user":{"displayName":"Eric Bianchi","photoUrl":"","userId":"05885933664328404224"}}},"source":["# paths to images\n","path_to_image = '/content/gdrive/Shareddrives/Advanced CV - Final Project/GradCAM/seed0608.jpeg'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"11IOdnpy8gBw"},"source":["gradCAM(path_to_image, model)"],"execution_count":null,"outputs":[]}]}